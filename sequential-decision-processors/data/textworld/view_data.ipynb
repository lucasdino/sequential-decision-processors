{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f056c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from raw.generation_util.parsing import pqt_extract_ground_truth\n",
    "from raw.utils.board import visual_to_fen, extract_visual\n",
    "from raw.utils.parsing import parse_fen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76399322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5775 items from JSONL file rejsampling_predictmove_balanced_5775.jsonl.\n",
      "Shuffled 5775 items.\n"
     ]
    }
   ],
   "source": [
    "task_split = \"train\"\n",
    "task_type = \"rejsampling\"\n",
    "\n",
    "# parent_dir = f\"cleaned/verl_tasks/{task_split}\"\n",
    "# filename = f\"{task_type}.parquet\"\n",
    "# filepath = os.path.join(parent_dir, filename)\n",
    "filename = \"rejsampling_predictmove_balanced_5775.jsonl\"\n",
    "filepath = f\"cleaned/train_data/{filename}\"\n",
    "\n",
    "# Load data agnostic to parquet / json / jsonl\n",
    "if filename.endswith('.parquet'):\n",
    "    df = pd.read_parquet(filepath)\n",
    "    data = df.to_dict('records')\n",
    "    print(f\"Loaded {len(data)} items from parquet file {filename}.\")\n",
    "elif filename.endswith('.json'):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"Loaded {len(data)} items from JSON file {filename}.\")\n",
    "elif filename.endswith('.jsonl'):\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    print(f\"Loaded {len(data)} items from JSONL file {filename}.\")\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file format: {filename}. Please use .parquet, .json, or .jsonl files.\")\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "# Need to coerce since we stringified the ground truth dict due to issues w/ parquet saving\n",
    "# for row in data:\n",
    "#     row['reward_model']['ground_truth'] = pqt_extract_ground_truth(row['reward_model']['ground_truth'], task_type = task_type)\n",
    "\n",
    "print(f\"Shuffled {len(data)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d10671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:\n",
      "------------------------\n",
      "Below is a chess board from your current game.\n",
      "\n",
      "8| r n . q . b n r\n",
      "7| p . . . p k . p\n",
      "6| . p . . . . p .\n",
      "5| . . p . p . . .\n",
      "4| . . . . . . . .\n",
      "3| . . . P . . P .\n",
      "2| P P P . . P . P\n",
      "1| R N B . K . . .\n",
      "   _ _ _ _ _ _ _ _\n",
      "   A B C D E F G H\n",
      "\n",
      "- It is Black’s turn to move.\n",
      "- Castling rights: White can castle queenside.\n",
      "- No en passant target square.\n",
      "- Halfmove clock: 0\n",
      "- Fullmove number: 12\n",
      "\n",
      "You must select the best move from this position and return it within answer tags. Your answer must be formatted as <answer> my_move </answer>, where my_move is a legal move in UCI notation.\n",
      "\n",
      "Think step by step if necessary, but do not omit the answer tags or UCI format. Only answers in the correct format will be accepted.\n",
      "\n",
      "\n",
      "assistant:\n",
      "------------------------\n",
      "<think>\n",
      "First, let's analyze the given position:\n",
      "The current state of the board is:\n",
      "8| r n . q . b n r\n",
      "7| p . . . p k . p\n",
      "6| . p . . . . p .\n",
      "5| . . p . p . . .\n",
      "4| . . . . . . . .\n",
      "3| . . . P . . P .\n",
      "2| P P P . . P . P\n",
      "1| R N B . K . . .\n",
      "\n",
      "It's Black's turn. We need to assess the position carefully.\n",
      "\n",
      "The first observation is that Black's king is somewhat exposed on e7, and there's no clear indication that it's going to castle soon since the kingside pieces haven't moved much. However, we also see that White's king is still in the center and hasn't castled yet, although it has the right to castle queenside.\n",
      "\n",
      "Let's examine potential threats and opportunities:\n",
      "\n",
      "1. **Black's Position**: \n",
      "   - The pawn structure suggests some flexibility with pawns on c5 and e5 potentially being played later, though they're not immediately available due to other piece placements.\n",
      "   - Black's knights are developed, and so are the bishops potentially, once they develop.\n",
      "   - There's pressure needed on White's central control.\n",
      "\n",
      "2. **White's Position**:\n",
      "   - Has a significant presence in the center due to the pawn on d4.\n",
      "   - White's development seems slower; their dark-squared bishop is undeveloped, and the queen isn't out yet.\n",
      "   - White's king might find safety via queenside castling.\n",
      "\n",
      "Given these observations, our goal should be to put pressure on White before they fully develop and secure their king.\n",
      "\n",
      "One immediate threat for Black could be developing pieces towards the center or targeting weak points in White's setup. \n",
      "\n",
      "Noting that White has not moved their f1 bishop or their queen, and considering Black's relatively safe position except for the slightly vulnerable king on e7, one idea is to play safely while putting pressure on White.\n",
      "\n",
      "A straightforward plan involves moving the f8 rook into play or preparing to develop other pieces effectively.\n",
      "\n",
      "Looking closely at possible moves, `g7g6` appears too passive without directly contributing to rapid development or attacking play. Let's evaluate more active options like knight moves or pushing central pawns when feasible.\n",
      "\n",
      "However, upon closer inspection, I notice that `b8c6` develops a piece, supports potential central pushes (`d7d5`), and doesn't overly expose Black. It's a solid developmental move.\n",
      "\n",
      "Another consideration is assessing whether there are direct attacks or tactical shots available. For instance, checking if any of White's under-developed status leaves them open to tactics.\n",
      "\n",
      "Upon deeper review, I believe `b8c6` fits well because it develops a piece harmoniously and gets ready for further actions such as controlling the center or supporting potential breaks.\n",
      "\n",
      "</think>\n",
      "\n",
      "<answer> b8c6 </answer>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(data)\n",
    "\n",
    "def print_data(datum):\n",
    "    for d in datum:\n",
    "        if d[0] == \"system\":\n",
    "            continue\n",
    "        print(f\"{d[0]}:\\n------------------------\\n{d[1]}\\n\\n\")\n",
    "\n",
    "print_data(data[0]['chat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4e3599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket   | Observed |  Desired\n",
      "------------------------------\n",
      "0-9      |   9.96% |  12.00%\n",
      "10-19    |  29.98% |  30.00%\n",
      "20-29    |  29.98% |  30.00%\n",
      "30-39    |  15.04% |  15.00%\n",
      "40-150   |  15.04% |  13.00%\n"
     ]
    }
   ],
   "source": [
    "# --- Config ------------------------------------------------------\n",
    "FULLMOVE_DEFAULT_BUCKETS = [\n",
    "    ((0, 9),   0.12),\n",
    "    ((10, 19), 0.30),\n",
    "    ((20, 29), 0.30),\n",
    "    ((30, 39), 0.15),\n",
    "    ((40, 150), 0.13),\n",
    "]\n",
    "\n",
    "# --- Collect counts ---------------------------------------------\n",
    "bucket_labels = [f\"{lo}-{hi}\" for (lo, hi), _ in FULLMOVE_DEFAULT_BUCKETS]\n",
    "counts = Counter({lbl: 0 for lbl in bucket_labels})\n",
    "total  = 0\n",
    "\n",
    "for row in data:\n",
    "    fullmove = parse_fen(visual_to_fen(extract_visual(row[\"prompt\"][1][\"content\"])))[\"fullmove_number\"]\n",
    "    for (lo, hi), _ in FULLMOVE_DEFAULT_BUCKETS:\n",
    "        if lo <= fullmove <= hi:\n",
    "            counts[f\"{lo}-{hi}\"] += 1\n",
    "            break\n",
    "    total += 1\n",
    "\n",
    "# --- Print table -------------------------------------------------\n",
    "print(f\"{'Bucket':<8} | {'Observed':>8} | {'Desired':>8}\")\n",
    "print(\"-\" * 30)\n",
    "for (lo, hi), desired in FULLMOVE_DEFAULT_BUCKETS:\n",
    "    lbl = f\"{lo}-{hi}\"\n",
    "    obs = counts[lbl] / total if total else 0\n",
    "    print(f\"{lbl:<8} | {obs:>7.2%} | {desired:>7.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a31297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System:\n",
      "You are a chess grandmaster currently playing against a strong opponent. Assume they will capitalize on any blunders you make.\n",
      "\n",
      "You are exceptional at thinking through various board states and strategically planning your next move. You are detail oriented, strategic, and an efficient thinker. You use all of these traits to be an effective chess player.\n",
      "\n",
      "Do not hallucinate. All statements should be based on the provided board and you must avoid considering pieces that do not exist or moves that are illegal.\n",
      "\n",
      "You must refer to moves in UCI notation (e.g., d7d5) and include your thinking in think tags (e.g., <think> your_thinking </think>) and your answer in answer tags (e.g., <answer> your_answer </answer>). If you do not need to reason heavily, you should still include think tags but with '\\n\\n' (e.g., <think> \\n\\n <\\think>).\n",
      "\n",
      "Finally, make sure to always think out loud (using the <think> tags) to convey your thought process as you consider various moves and solutions to puzzles you are provided.\n",
      "\n",
      "User:\n",
      "Below is a board in a game you're currently playing.\n",
      "\n",
      "8| . . k . . . r .\n",
      "7| b p p . . . . .\n",
      "6| p . . p . . . p\n",
      "5| P . . q . . . .\n",
      "4| . P . P . p r .\n",
      "3| . . . Q . N . .\n",
      "2| . . . . . P P B\n",
      "1| R . . . R . K .\n",
      "   _ _ _ _ _ _ _ _\n",
      "   A B C D E F G H\n",
      "\n",
      "- It is White’s turn to move.\n",
      "- No castling rights available.\n",
      "- No en passant target square.\n",
      "- Halfmove clock: 1\n",
      "- Fullmove number: 27\n",
      "    \n",
      "You must choose the best move from the following moves: ['e1e4', 'e1c1', 'd3f5', 'e1e8', 'd3e3']. \n",
      "\n",
      "You may want to think out loud to help finalize your answer. However, you must provide your answer within answer tags (e.g., <answer> move_choice </answer>).\n",
      "\n",
      "The move must be provided in UCI notation and within answer tags in order to be accepted.\n",
      "\n",
      "Ground Truth:\n",
      "{'answer': 'e1e4', 'candidates': ['e1e4', 'e1c1', 'd3f5', 'e1e8', 'd3e3']}\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample / print data\n",
    "sample = random.choice(data)\n",
    "# for key, value in sample.items():\n",
    "#     print(key)\n",
    "#     print(type(value))\n",
    "#     print(f\"{value}\\n{'-'*60}\\n\")\n",
    "\n",
    "sys_prompt  = sample['prompt'][0]\n",
    "user_prompt = sample['prompt'][1]\n",
    "ground_truth = sample['reward_model']['ground_truth']\n",
    "\n",
    "print(f\"System:\\n{sys_prompt['content']}\\n\")\n",
    "print(f\"User:\\n{user_prompt['content']}\\n\")\n",
    "print(f\"Ground Truth:\\n{ground_truth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d814f",
   "metadata": {},
   "source": [
    "## Code to clean up / concatenate existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# parent_dir = \"explainer_data\"\n",
    "# filenames = [\n",
    "#     \"explainer_clean_100_1558_15.parquet\",\n",
    "#     \"explainer_clean_1250.parquet\",\n",
    "#     \"explanations_0_1000_0104_16.parquet\",\n",
    "#     \"explanations_1_1000_0330_16.parquet\",\n",
    "#     \"explanations_2_1000_0557_16.parquet\",\n",
    "#     \"explanations_3_1000_0826_16.parquet\"\n",
    "# ]\n",
    "# filepaths = [os.path.join(parent_dir, fn) for fn in filenames]\n",
    "# output_file = \"combined_chessexplainer.jsonl\"\n",
    "# system_prompt_file = \"chess_task_sysprompt.txt\"  # Or \"llama4_default_sysprompt.txt\"\n",
    "\n",
    "\n",
    "# HEADER_PATTERN = re.compile(\n",
    "#     r\"<\\|start_header_id\\|>(\\w+)<\\|end_header_id\\|>\\n?(.*?)(?=(<\\|start_header_id\\|>|\\Z|<\\|eot_id\\|>))\",\n",
    "#     re.DOTALL\n",
    "# )\n",
    "\n",
    "# def extract_dialogue(sample):\n",
    "#     text = sample['prompt']\n",
    "#     result = []\n",
    "#     for match in HEADER_PATTERN.finditer(text):\n",
    "#         role, content = match.group(1), match.group(2).strip()\n",
    "#         # Remove Llama tags and both eot_id types\n",
    "#         content = re.sub(r\"<\\|.*?\\|>|<eot_id>\", \"\", content).strip()\n",
    "#         if role == \"system\":\n",
    "#             content = \"chess_task_sysprompt.txt\"\n",
    "#         if role == \"user\":\n",
    "#             prefix = \"Here is a board in a game you're currently playing. I want you to think through some possible moves you could make and how those moves will likely play out. You may find it helpful to roll-out each line assuming your opponent plays near-optimally. You may also find it helpful to consider the value of the final board state after each roll-out.\\n\\nAfter you think through your various moves, please end by telling me your chosen move (in UCI notation) within answer tags.\\n\\n\"\n",
    "#             content = prefix + content\n",
    "#         if content:\n",
    "#             result.append((role, content))\n",
    "#     completion = sample.get('completion', '').strip()\n",
    "#     completion = re.sub(r'(<\\|eot_id\\|>|<eot_id>)\\s*$', '', completion).strip()\n",
    "#     if completion:\n",
    "#         result.append(('assistant', completion))\n",
    "#     return result\n",
    "\n",
    "# def convert_and_save(parquet_paths, output_path):\n",
    "#     all_dialogues = []\n",
    "#     for path in parquet_paths:\n",
    "#         df = pd.read_parquet(path)\n",
    "#         all_dialogues.extend(\n",
    "#             {\"chat\": extract_dialogue(row)} for row in df.to_dict('records')\n",
    "#         )\n",
    "#     # Save as JSONL\n",
    "#     with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#         for d in all_dialogues:\n",
    "#             json.dump(d, f, ensure_ascii=False)\n",
    "#             f.write('\\n')\n",
    "#     print(f\"Saved {len(all_dialogues)} dialogues to {output_path}\")\n",
    "\n",
    "\n",
    "# output_path = os.path.join(parent_dir, output_file)\n",
    "# convert_and_save(filepaths, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d862fe95",
   "metadata": {},
   "source": [
    "## Code to Count Length of Responses in the Model Responses Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df27563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llmchess-llama31-8b-400: 1052.18\n",
      "llmchess-llama31-8b-sft-mmxl-400: 3376.89\n",
      "llmchess-llama33-70b-400: 1957.45\n",
      "llmchess-llama4-scout-400: 1824.58\n",
      "llmchess-qwen25-7b-400: 917.69\n",
      "llmchess-qwen25-7b-grpo-datamix-2-400: 2513.86\n",
      "llmchess-qwen25-7b-grpo-mmxl-400: 2932.48\n",
      "llmchess-qwen25-7b-sft-dm2-v2-400: 4330.30\n",
      "llmchess-qwen25-7b-sft-mmxl-400: 4130.17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "BASE_DIR = \"cleaned/model_responses\"\n",
    "\n",
    "for folder in os.listdir(BASE_DIR):\n",
    "    folder_path = os.path.join(BASE_DIR, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    response_lengths = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if not file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            for elem in data:\n",
    "                resp = elem.get(\"model_response\", \"\")\n",
    "                response_lengths.append(len(resp))\n",
    "\n",
    "    if response_lengths:\n",
    "        mean_length = sum(response_lengths) / len(response_lengths)\n",
    "        print(f\"{folder}: {mean_length:.2f}\")\n",
    "    else:\n",
    "        print(f\"{folder}: No model responses found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a7ca1",
   "metadata": {},
   "source": [
    "# Code to split my XL_Dataset (15mm samples, 10GB) into 10 equal sized chunks to be uploaded to the S3 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6a9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split a ~10 GB JSON array (~15 M rows) into 10 ≈1 GB shards\n",
    "without ever holding more than a handful of objects in RAM.\n",
    "\n",
    "– Input   :  ./llamafactory_programmatic_15mm.json\n",
    "             ⟶ one big JSON array `[ { … }, { … }, … ]`\n",
    "– Outputs :  preprocessed_train_data/xl_run/xl_sft_p<N>/\n",
    "               ├─ llamafactory_programmatic_<rows>.json   (the shard)\n",
    "               └─ dataset_info.json                       (schema-meta)\n",
    "\n",
    "Requires:  ijson  (streaming JSON parser)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, math, os, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import ijson\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Configuration\n",
    "##############################################################################\n",
    "\n",
    "IN_FILE   = Path(\"llamafactory_programmatic_8984647.json\")\n",
    "OUT_ROOT  = Path(\"preprocessed_train_data/new_uploads/exp_29\")\n",
    "NUM_PARTS = 4  # target number of ~1 GB shards\n",
    "RUN_SPLIT = True\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Helper – stream-count objects (cheap in RAM, just slow I/O)\n",
    "##############################################################################\n",
    "\n",
    "def count_rows(path: Path) -> int:\n",
    "    n = 0\n",
    "    with path.open(\"rb\") as fh:\n",
    "        for _ in ijson.items(fh, \"item\"):   # top-level “item” = each dict\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Helper – open/close a shard in streaming-write mode\n",
    "##############################################################################\n",
    "\n",
    "def open_shard(index: int) -> tuple[os.PathLike, object, int]:\n",
    "    \"\"\"\n",
    "    Create   preprocessed_train_data/xl_run/xl_sft_p<index>/temp.json\n",
    "    and write initial “[”.\n",
    "    \"\"\"\n",
    "    shard_dir = OUT_ROOT / f\"xl_sft_p{index}\"\n",
    "    shard_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    temp_path = shard_dir / \"tmp.json\"\n",
    "    fh = temp_path.open(\"w\", encoding=\"utf-8\")\n",
    "    fh.write(\"[\")           # start JSON array\n",
    "\n",
    "    return shard_dir, fh, 0   # last value == objects written so far\n",
    "\n",
    "\n",
    "def close_shard(shard_dir: Path, fh, rows_written: int) -> None:\n",
    "    \"\"\"\n",
    "    Finish JSON array, rename file to include row-count, drop dataset_info.json.\n",
    "    \"\"\"\n",
    "    fh.write(\"]\\n\")\n",
    "    fh.close()\n",
    "\n",
    "    final_name = f\"llamafactory_programmatic_{rows_written}.json\"\n",
    "    final_path = shard_dir / final_name\n",
    "    os.rename(shard_dir / \"tmp.json\", final_path)\n",
    "\n",
    "    info = {\n",
    "        \"llmchess_programmatic\": {\n",
    "            \"file_name\": final_name,\n",
    "            \"columns\": {\n",
    "                \"system\": \"system\",\n",
    "                \"prompt\": \"user\",\n",
    "                \"response\": \"assistant\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    with (shard_dir / \"dataset_info.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(info, f, indent=2)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Main\n",
    "##############################################################################\n",
    "\n",
    "def split_big_json() -> None:\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    total_rows = count_rows(IN_FILE)\n",
    "    rows_per_part = math.ceil(total_rows / NUM_PARTS)\n",
    "\n",
    "    shard_idx              = 1\n",
    "    shard_dir, out_fh, n   = open_shard(shard_idx)\n",
    "    first_in_shard         = True\n",
    "\n",
    "    with IN_FILE.open(\"rb\") as in_fh:\n",
    "        for obj in ijson.items(in_fh, \"item\"):\n",
    "            # rotate shard when full\n",
    "            if n == rows_per_part:\n",
    "                close_shard(shard_dir, out_fh, n)\n",
    "                shard_idx += 1\n",
    "                shard_dir, out_fh, n = open_shard(shard_idx)\n",
    "                first_in_shard = True\n",
    "\n",
    "            # streaming-write the current object\n",
    "            if not first_in_shard:\n",
    "                out_fh.write(\",\\n\")\n",
    "            json.dump(obj, out_fh)\n",
    "            first_in_shard = False\n",
    "            n += 1\n",
    "\n",
    "    # final shard\n",
    "    close_shard(shard_dir, out_fh, n)\n",
    "\n",
    "\n",
    "if RUN_SPLIT:\n",
    "    split_big_json()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
